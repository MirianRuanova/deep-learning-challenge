{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zolSUUJVsdCQ"
      },
      "outputs": [],
      "source": [
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "#  Import and read the charity_data.csv.\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
        "application_df = application_df.drop(columns=[\"EIN\", \"NAME\"])\n",
        "application_df.nunique()\n",
        "application_type_counts = application_df[\"APPLICATION_TYPE\"].value_counts().to_dict()\n",
        "cutoff_value = 527\n",
        "application_types_to_replace = []\n",
        "for atype in application_type_counts:\n",
        "    if application_type_counts[atype] < cutoff_value:\n",
        "        application_types_to_replace.append(atype)\n",
        "# Replace in dataframe\n",
        "# After creating the application_types_to_replace list,\n",
        "# another for loop is used to replace the application types in the \"APPLICATION_TYPE\" column of the DataFrame with \"Other\".\n",
        "# This ensures that the application types identified in the application_types_to_replace list are replaced accordingly.\n",
        "for app in application_types_to_replace:\n",
        "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
        "\n",
        "# Check to make sure binning was successful\n",
        "application_df['APPLICATION_TYPE'].value_counts()\n",
        "classifications_counts = application_df[\"CLASSIFICATION\"].value_counts().to_dict()\n",
        "cutoff_value_c = 1882\n",
        "classifications_to_replace = []\n",
        "for classf in classifications_counts:\n",
        "    if classifications_counts[classf] < cutoff_value_c:\n",
        "        classifications_to_replace.append(classf)\n",
        "\n",
        "# Replace in dataframe\n",
        "for cls in classifications_to_replace:\n",
        "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
        "\n",
        "\n",
        "categorical_columns = ['APPLICATION_TYPE', 'AFFILIATION', 'CLASSIFICATION', 'USE_CASE', 'ORGANIZATION', 'INCOME_AMT', 'SPECIAL_CONSIDERATIONS']\n",
        "\n",
        "\n",
        "dummy_df = pd.get_dummies(application_df[categorical_columns], columns=categorical_columns)\n",
        "\n",
        "\n",
        "\n",
        "application_df.drop(columns=categorical_columns, inplace=True)\n",
        "\n",
        "application_df = pd.concat([application_df, dummy_df], axis=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "PouG6hVjsrdE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z0pXRvxbtRB0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attempt 1:"
      ],
      "metadata": {
        "id": "gG5aJUOGx_u3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_columns_with_outliers_iqr(df, lower_percentile=25, upper_percentile=75, multiplier=1.5):\n",
        "    # Initialize an empty list to store column names with outliers\n",
        "    columns_with_outliers = []\n",
        "\n",
        "    # Loop through each column in the DataFrame\n",
        "    for column_name in df.columns:\n",
        "        # Calculate the IQR for the column\n",
        "        Q1 = df[column_name].quantile(lower_percentile / 100)\n",
        "        Q3 = df[column_name].quantile(upper_percentile / 100)\n",
        "        IQR = Q3 - Q1\n",
        "\n",
        "        # Define the lower and upper bounds to identify outliers\n",
        "        lower_bound = Q1 - multiplier * IQR\n",
        "        upper_bound = Q3 + multiplier * IQR\n",
        "\n",
        "        # Check if any value is outside the bounds\n",
        "        if any((df[column_name] < lower_bound) | (df[column_name] > upper_bound)):\n",
        "            columns_with_outliers.append(column_name)\n",
        "\n",
        "    return columns_with_outliers\n",
        "\n",
        "\n",
        "def drop_outliers_iqr(df, column_name, lower_percentile=25, upper_percentile=75, multiplier=1.5):\n",
        "    # Calculate the IQR for the specified column\n",
        "    Q1 = df[column_name].quantile(lower_percentile / 100)\n",
        "    Q3 = df[column_name].quantile(upper_percentile / 100)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    # Define the lower and upper bounds to identify outliers\n",
        "    lower_bound = Q1 - multiplier * IQR\n",
        "    upper_bound = Q3 + multiplier * IQR\n",
        "\n",
        "    # Drop rows with values outside the bounds\n",
        "    df_cleaned = df[(df[column_name] >= lower_bound) & (df[column_name] <= upper_bound)]\n",
        "\n",
        "    return df_cleaned\n",
        "\n"
      ],
      "metadata": {
        "id": "oJnsP4ofttui"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=application_df['IS_SUCCESSFUL']\n",
        "x = application_df.drop(columns=['IS_SUCCESSFUL'])\n",
        "print(x.shape)\n",
        "columns_with_outliers = detect_columns_with_outliers_iqr(x, lower_percentile=25, upper_percentile=75, multiplier=1.5)\n",
        "print(\"Columns with outliers based on IQR:\", columns_with_outliers)\n",
        "for c in columns_with_outliers:\n",
        "  x=drop_outliers_iqr(x,c,lower_percentile=25, upper_percentile=75, multiplier=1.5)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbc1yWjCuxUj",
        "outputId": "48b318d7-4154-4f54-f577-4981c883af90"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(34299, 43)\n",
            "Columns with outliers based on IQR: ['STATUS', 'ASK_AMT', 'APPLICATION_TYPE_Other', 'APPLICATION_TYPE_T10', 'APPLICATION_TYPE_T19', 'APPLICATION_TYPE_T3', 'APPLICATION_TYPE_T4', 'APPLICATION_TYPE_T5', 'APPLICATION_TYPE_T6', 'APPLICATION_TYPE_T7', 'APPLICATION_TYPE_T8', 'AFFILIATION_Family/Parent', 'AFFILIATION_National', 'AFFILIATION_Other', 'AFFILIATION_Regional', 'CLASSIFICATION_C1200', 'CLASSIFICATION_C2000', 'CLASSIFICATION_C2100', 'CLASSIFICATION_C3000', 'CLASSIFICATION_Other', 'USE_CASE_CommunityServ', 'USE_CASE_Heathcare', 'USE_CASE_Other', 'USE_CASE_Preservation', 'USE_CASE_ProductDev', 'ORGANIZATION_Co-operative', 'ORGANIZATION_Corporation', 'INCOME_AMT_1-9999', 'INCOME_AMT_10000-24999', 'INCOME_AMT_100000-499999', 'INCOME_AMT_10M-50M', 'INCOME_AMT_1M-5M', 'INCOME_AMT_25000-99999', 'INCOME_AMT_50M+', 'INCOME_AMT_5M-10M', 'SPECIAL_CONSIDERATIONS_N', 'SPECIAL_CONSIDERATIONS_Y']\n",
            "(11478, 43)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "x9IEqjsvu8aJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_nn = tf.keras.models.Sequential()\n",
        "\n",
        "# Input layer\n",
        "new_nn.add(tf.keras.layers.InputLayer(input_shape=(X_train_scaled.shape[1],)))\n",
        "\n",
        "# First hidden layer with 64 neurons and ReLU activation\n",
        "new_nn.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
        "\n",
        "# Dropout layer to reduce overfitting\n",
        "new_nn.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "# Second hidden layer with 32 neurons and ReLU activation\n",
        "new_nn.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
        "\n",
        "# Third hidden layer with 16 neurons and ReLU activation\n",
        "new_nn.add(tf.keras.layers.Dense(units=16, activation='relu'))\n",
        "\n",
        "# Fourth hidden layer with 8 neurons and ReLU activation\n",
        "new_nn.add(tf.keras.layers.Dense(units=8, activation='relu'))\n",
        "\n",
        "# Output layer with 1 neuron and sigmoid activation for binary classification\n",
        "new_nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Compile the new model\n",
        "new_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Check the summary of the new model\n",
        "new_nn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGMLielLvn9W",
        "outputId": "5b93ca25-1b04-4a92-dafa-a14064501d34"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                2816      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,569\n",
            "Trainable params: 5,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=150\n",
        "batch_size=32\n",
        "new_nn.fit(X_train_scaled, y_train, epochs=num_epochs, batch_size=batch_size, validation_data=(X_test_scaled, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSUg8gFXv5Dr",
        "outputId": "f5dea9cd-f128-4db2-9bb1-d96b1e5d38ac"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "858/858 [==============================] - 5s 3ms/step - loss: 0.5846 - accuracy: 0.7112 - val_loss: 0.5670 - val_accuracy: 0.7223\n",
            "Epoch 2/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5631 - accuracy: 0.7266 - val_loss: 0.5611 - val_accuracy: 0.7233\n",
            "Epoch 3/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5581 - accuracy: 0.7284 - val_loss: 0.5577 - val_accuracy: 0.7265\n",
            "Epoch 4/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5558 - accuracy: 0.7281 - val_loss: 0.5581 - val_accuracy: 0.7257\n",
            "Epoch 5/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5523 - accuracy: 0.7292 - val_loss: 0.5633 - val_accuracy: 0.7248\n",
            "Epoch 6/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5521 - accuracy: 0.7307 - val_loss: 0.5583 - val_accuracy: 0.7259\n",
            "Epoch 7/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5518 - accuracy: 0.7316 - val_loss: 0.5582 - val_accuracy: 0.7273\n",
            "Epoch 8/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5496 - accuracy: 0.7315 - val_loss: 0.5583 - val_accuracy: 0.7258\n",
            "Epoch 9/150\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5502 - accuracy: 0.7320 - val_loss: 0.5614 - val_accuracy: 0.7290\n",
            "Epoch 10/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5499 - accuracy: 0.7320 - val_loss: 0.5581 - val_accuracy: 0.7268\n",
            "Epoch 11/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5488 - accuracy: 0.7311 - val_loss: 0.5550 - val_accuracy: 0.7299\n",
            "Epoch 12/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5488 - accuracy: 0.7321 - val_loss: 0.5564 - val_accuracy: 0.7274\n",
            "Epoch 13/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5472 - accuracy: 0.7321 - val_loss: 0.5570 - val_accuracy: 0.7277\n",
            "Epoch 14/150\n",
            "858/858 [==============================] - 5s 6ms/step - loss: 0.5483 - accuracy: 0.7322 - val_loss: 0.5578 - val_accuracy: 0.7287\n",
            "Epoch 15/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5485 - accuracy: 0.7329 - val_loss: 0.5553 - val_accuracy: 0.7297\n",
            "Epoch 16/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5473 - accuracy: 0.7333 - val_loss: 0.5558 - val_accuracy: 0.7255\n",
            "Epoch 17/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5468 - accuracy: 0.7332 - val_loss: 0.5560 - val_accuracy: 0.7284\n",
            "Epoch 18/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5469 - accuracy: 0.7340 - val_loss: 0.5553 - val_accuracy: 0.7315\n",
            "Epoch 19/150\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5467 - accuracy: 0.7348 - val_loss: 0.5567 - val_accuracy: 0.7296\n",
            "Epoch 20/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5453 - accuracy: 0.7345 - val_loss: 0.5572 - val_accuracy: 0.7211\n",
            "Epoch 21/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5459 - accuracy: 0.7337 - val_loss: 0.5566 - val_accuracy: 0.7273\n",
            "Epoch 22/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5458 - accuracy: 0.7336 - val_loss: 0.5565 - val_accuracy: 0.7261\n",
            "Epoch 23/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5457 - accuracy: 0.7342 - val_loss: 0.5556 - val_accuracy: 0.7271\n",
            "Epoch 24/150\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5445 - accuracy: 0.7348 - val_loss: 0.5573 - val_accuracy: 0.7262\n",
            "Epoch 25/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5448 - accuracy: 0.7350 - val_loss: 0.5563 - val_accuracy: 0.7262\n",
            "Epoch 26/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5452 - accuracy: 0.7345 - val_loss: 0.5557 - val_accuracy: 0.7265\n",
            "Epoch 27/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5451 - accuracy: 0.7340 - val_loss: 0.5556 - val_accuracy: 0.7268\n",
            "Epoch 28/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5449 - accuracy: 0.7349 - val_loss: 0.5573 - val_accuracy: 0.7251\n",
            "Epoch 29/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5440 - accuracy: 0.7342 - val_loss: 0.5567 - val_accuracy: 0.7255\n",
            "Epoch 30/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5446 - accuracy: 0.7344 - val_loss: 0.5566 - val_accuracy: 0.7257\n",
            "Epoch 31/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5436 - accuracy: 0.7351 - val_loss: 0.5556 - val_accuracy: 0.7262\n",
            "Epoch 32/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5436 - accuracy: 0.7347 - val_loss: 0.5565 - val_accuracy: 0.7249\n",
            "Epoch 33/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5433 - accuracy: 0.7348 - val_loss: 0.5560 - val_accuracy: 0.7277\n",
            "Epoch 34/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5434 - accuracy: 0.7352 - val_loss: 0.5560 - val_accuracy: 0.7274\n",
            "Epoch 35/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5426 - accuracy: 0.7352 - val_loss: 0.5568 - val_accuracy: 0.7280\n",
            "Epoch 36/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5434 - accuracy: 0.7354 - val_loss: 0.5564 - val_accuracy: 0.7264\n",
            "Epoch 37/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5426 - accuracy: 0.7349 - val_loss: 0.5575 - val_accuracy: 0.7267\n",
            "Epoch 38/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5430 - accuracy: 0.7355 - val_loss: 0.5575 - val_accuracy: 0.7230\n",
            "Epoch 39/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5420 - accuracy: 0.7359 - val_loss: 0.5556 - val_accuracy: 0.7273\n",
            "Epoch 40/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5423 - accuracy: 0.7353 - val_loss: 0.5560 - val_accuracy: 0.7258\n",
            "Epoch 41/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5425 - accuracy: 0.7355 - val_loss: 0.5565 - val_accuracy: 0.7274\n",
            "Epoch 42/150\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5425 - accuracy: 0.7373 - val_loss: 0.5580 - val_accuracy: 0.7258\n",
            "Epoch 43/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5423 - accuracy: 0.7361 - val_loss: 0.5593 - val_accuracy: 0.7273\n",
            "Epoch 44/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5425 - accuracy: 0.7357 - val_loss: 0.5567 - val_accuracy: 0.7226\n",
            "Epoch 45/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5419 - accuracy: 0.7357 - val_loss: 0.5580 - val_accuracy: 0.7261\n",
            "Epoch 46/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5414 - accuracy: 0.7368 - val_loss: 0.5572 - val_accuracy: 0.7277\n",
            "Epoch 47/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5424 - accuracy: 0.7351 - val_loss: 0.5567 - val_accuracy: 0.7257\n",
            "Epoch 48/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5418 - accuracy: 0.7364 - val_loss: 0.5562 - val_accuracy: 0.7306\n",
            "Epoch 49/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5418 - accuracy: 0.7364 - val_loss: 0.5577 - val_accuracy: 0.7286\n",
            "Epoch 50/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5416 - accuracy: 0.7363 - val_loss: 0.5591 - val_accuracy: 0.7254\n",
            "Epoch 51/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5411 - accuracy: 0.7360 - val_loss: 0.5583 - val_accuracy: 0.7255\n",
            "Epoch 52/150\n",
            "858/858 [==============================] - 4s 4ms/step - loss: 0.5402 - accuracy: 0.7378 - val_loss: 0.5619 - val_accuracy: 0.7222\n",
            "Epoch 53/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5418 - accuracy: 0.7359 - val_loss: 0.5582 - val_accuracy: 0.7281\n",
            "Epoch 54/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5411 - accuracy: 0.7359 - val_loss: 0.5563 - val_accuracy: 0.7299\n",
            "Epoch 55/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5409 - accuracy: 0.7373 - val_loss: 0.5577 - val_accuracy: 0.7292\n",
            "Epoch 56/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5411 - accuracy: 0.7368 - val_loss: 0.5581 - val_accuracy: 0.7252\n",
            "Epoch 57/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5413 - accuracy: 0.7369 - val_loss: 0.5581 - val_accuracy: 0.7242\n",
            "Epoch 58/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5411 - accuracy: 0.7368 - val_loss: 0.5581 - val_accuracy: 0.7229\n",
            "Epoch 59/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5411 - accuracy: 0.7360 - val_loss: 0.5580 - val_accuracy: 0.7243\n",
            "Epoch 60/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5402 - accuracy: 0.7370 - val_loss: 0.5576 - val_accuracy: 0.7267\n",
            "Epoch 61/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5405 - accuracy: 0.7367 - val_loss: 0.5581 - val_accuracy: 0.7259\n",
            "Epoch 62/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5399 - accuracy: 0.7357 - val_loss: 0.5574 - val_accuracy: 0.7265\n",
            "Epoch 63/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5403 - accuracy: 0.7362 - val_loss: 0.5589 - val_accuracy: 0.7271\n",
            "Epoch 64/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5401 - accuracy: 0.7375 - val_loss: 0.5577 - val_accuracy: 0.7230\n",
            "Epoch 65/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5400 - accuracy: 0.7361 - val_loss: 0.5581 - val_accuracy: 0.7289\n",
            "Epoch 66/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5407 - accuracy: 0.7372 - val_loss: 0.5573 - val_accuracy: 0.7283\n",
            "Epoch 67/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5403 - accuracy: 0.7369 - val_loss: 0.5588 - val_accuracy: 0.7262\n",
            "Epoch 68/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5406 - accuracy: 0.7358 - val_loss: 0.5595 - val_accuracy: 0.7255\n",
            "Epoch 69/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5405 - accuracy: 0.7363 - val_loss: 0.5583 - val_accuracy: 0.7238\n",
            "Epoch 70/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5399 - accuracy: 0.7369 - val_loss: 0.5573 - val_accuracy: 0.7242\n",
            "Epoch 71/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5399 - accuracy: 0.7375 - val_loss: 0.5576 - val_accuracy: 0.7264\n",
            "Epoch 72/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5397 - accuracy: 0.7369 - val_loss: 0.5586 - val_accuracy: 0.7274\n",
            "Epoch 73/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5408 - accuracy: 0.7358 - val_loss: 0.5579 - val_accuracy: 0.7273\n",
            "Epoch 74/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5394 - accuracy: 0.7364 - val_loss: 0.5601 - val_accuracy: 0.7227\n",
            "Epoch 75/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5399 - accuracy: 0.7369 - val_loss: 0.5598 - val_accuracy: 0.7276\n",
            "Epoch 76/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5396 - accuracy: 0.7368 - val_loss: 0.5583 - val_accuracy: 0.7274\n",
            "Epoch 77/150\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5406 - accuracy: 0.7363 - val_loss: 0.5582 - val_accuracy: 0.7278\n",
            "Epoch 78/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5393 - accuracy: 0.7372 - val_loss: 0.5596 - val_accuracy: 0.7245\n",
            "Epoch 79/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5392 - accuracy: 0.7365 - val_loss: 0.5578 - val_accuracy: 0.7246\n",
            "Epoch 80/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5392 - accuracy: 0.7367 - val_loss: 0.5584 - val_accuracy: 0.7276\n",
            "Epoch 81/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5392 - accuracy: 0.7379 - val_loss: 0.5594 - val_accuracy: 0.7223\n",
            "Epoch 82/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5386 - accuracy: 0.7367 - val_loss: 0.5600 - val_accuracy: 0.7280\n",
            "Epoch 83/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5387 - accuracy: 0.7374 - val_loss: 0.5595 - val_accuracy: 0.7262\n",
            "Epoch 84/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5396 - accuracy: 0.7382 - val_loss: 0.5602 - val_accuracy: 0.7277\n",
            "Epoch 85/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5397 - accuracy: 0.7368 - val_loss: 0.5592 - val_accuracy: 0.7226\n",
            "Epoch 86/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5394 - accuracy: 0.7379 - val_loss: 0.5592 - val_accuracy: 0.7252\n",
            "Epoch 87/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5384 - accuracy: 0.7387 - val_loss: 0.5598 - val_accuracy: 0.7262\n",
            "Epoch 88/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5391 - accuracy: 0.7369 - val_loss: 0.5598 - val_accuracy: 0.7252\n",
            "Epoch 89/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5385 - accuracy: 0.7376 - val_loss: 0.5592 - val_accuracy: 0.7210\n",
            "Epoch 90/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5385 - accuracy: 0.7376 - val_loss: 0.5609 - val_accuracy: 0.7254\n",
            "Epoch 91/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5391 - accuracy: 0.7377 - val_loss: 0.5600 - val_accuracy: 0.7214\n",
            "Epoch 92/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5389 - accuracy: 0.7369 - val_loss: 0.5604 - val_accuracy: 0.7255\n",
            "Epoch 93/150\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5384 - accuracy: 0.7369 - val_loss: 0.5610 - val_accuracy: 0.7259\n",
            "Epoch 94/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5385 - accuracy: 0.7377 - val_loss: 0.5594 - val_accuracy: 0.7271\n",
            "Epoch 95/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5387 - accuracy: 0.7378 - val_loss: 0.5596 - val_accuracy: 0.7255\n",
            "Epoch 96/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5379 - accuracy: 0.7390 - val_loss: 0.5604 - val_accuracy: 0.7259\n",
            "Epoch 97/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5380 - accuracy: 0.7380 - val_loss: 0.5581 - val_accuracy: 0.7267\n",
            "Epoch 98/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5379 - accuracy: 0.7374 - val_loss: 0.5589 - val_accuracy: 0.7284\n",
            "Epoch 99/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5387 - accuracy: 0.7371 - val_loss: 0.5591 - val_accuracy: 0.7270\n",
            "Epoch 100/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5386 - accuracy: 0.7373 - val_loss: 0.5621 - val_accuracy: 0.7222\n",
            "Epoch 101/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5392 - accuracy: 0.7384 - val_loss: 0.5604 - val_accuracy: 0.7230\n",
            "Epoch 102/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5386 - accuracy: 0.7372 - val_loss: 0.5620 - val_accuracy: 0.7273\n",
            "Epoch 103/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5382 - accuracy: 0.7379 - val_loss: 0.5620 - val_accuracy: 0.7226\n",
            "Epoch 104/150\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5373 - accuracy: 0.7387 - val_loss: 0.5627 - val_accuracy: 0.7284\n",
            "Epoch 105/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5387 - accuracy: 0.7378 - val_loss: 0.5606 - val_accuracy: 0.7217\n",
            "Epoch 106/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5385 - accuracy: 0.7379 - val_loss: 0.5612 - val_accuracy: 0.7214\n",
            "Epoch 107/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5381 - accuracy: 0.7381 - val_loss: 0.5620 - val_accuracy: 0.7261\n",
            "Epoch 108/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5383 - accuracy: 0.7384 - val_loss: 0.5625 - val_accuracy: 0.7286\n",
            "Epoch 109/150\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5386 - accuracy: 0.7380 - val_loss: 0.5609 - val_accuracy: 0.7265\n",
            "Epoch 110/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5382 - accuracy: 0.7380 - val_loss: 0.5617 - val_accuracy: 0.7280\n",
            "Epoch 111/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5374 - accuracy: 0.7382 - val_loss: 0.5612 - val_accuracy: 0.7230\n",
            "Epoch 112/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5379 - accuracy: 0.7384 - val_loss: 0.5608 - val_accuracy: 0.7281\n",
            "Epoch 113/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5386 - accuracy: 0.7372 - val_loss: 0.5597 - val_accuracy: 0.7239\n",
            "Epoch 114/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5381 - accuracy: 0.7370 - val_loss: 0.5596 - val_accuracy: 0.7254\n",
            "Epoch 115/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5377 - accuracy: 0.7380 - val_loss: 0.5604 - val_accuracy: 0.7259\n",
            "Epoch 116/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5376 - accuracy: 0.7385 - val_loss: 0.5598 - val_accuracy: 0.7274\n",
            "Epoch 117/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5372 - accuracy: 0.7381 - val_loss: 0.5601 - val_accuracy: 0.7226\n",
            "Epoch 118/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5380 - accuracy: 0.7391 - val_loss: 0.5622 - val_accuracy: 0.7252\n",
            "Epoch 119/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5382 - accuracy: 0.7380 - val_loss: 0.5605 - val_accuracy: 0.7262\n",
            "Epoch 120/150\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5375 - accuracy: 0.7387 - val_loss: 0.5607 - val_accuracy: 0.7232\n",
            "Epoch 121/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5376 - accuracy: 0.7398 - val_loss: 0.5621 - val_accuracy: 0.7270\n",
            "Epoch 122/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5381 - accuracy: 0.7372 - val_loss: 0.5638 - val_accuracy: 0.7261\n",
            "Epoch 123/150\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5384 - accuracy: 0.7369 - val_loss: 0.5620 - val_accuracy: 0.7255\n",
            "Epoch 124/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5374 - accuracy: 0.7371 - val_loss: 0.5605 - val_accuracy: 0.7236\n",
            "Epoch 125/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5376 - accuracy: 0.7373 - val_loss: 0.5593 - val_accuracy: 0.7280\n",
            "Epoch 126/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5374 - accuracy: 0.7376 - val_loss: 0.5623 - val_accuracy: 0.7280\n",
            "Epoch 127/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5370 - accuracy: 0.7392 - val_loss: 0.5627 - val_accuracy: 0.7223\n",
            "Epoch 128/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5383 - accuracy: 0.7378 - val_loss: 0.5618 - val_accuracy: 0.7289\n",
            "Epoch 129/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5374 - accuracy: 0.7370 - val_loss: 0.5604 - val_accuracy: 0.7290\n",
            "Epoch 130/150\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5369 - accuracy: 0.7381 - val_loss: 0.5615 - val_accuracy: 0.7230\n",
            "Epoch 131/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5376 - accuracy: 0.7381 - val_loss: 0.5616 - val_accuracy: 0.7239\n",
            "Epoch 132/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5376 - accuracy: 0.7367 - val_loss: 0.5624 - val_accuracy: 0.7267\n",
            "Epoch 133/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5376 - accuracy: 0.7388 - val_loss: 0.5625 - val_accuracy: 0.7241\n",
            "Epoch 134/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5379 - accuracy: 0.7378 - val_loss: 0.5613 - val_accuracy: 0.7238\n",
            "Epoch 135/150\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5372 - accuracy: 0.7375 - val_loss: 0.5617 - val_accuracy: 0.7287\n",
            "Epoch 136/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5369 - accuracy: 0.7375 - val_loss: 0.5626 - val_accuracy: 0.7283\n",
            "Epoch 137/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5373 - accuracy: 0.7367 - val_loss: 0.5620 - val_accuracy: 0.7268\n",
            "Epoch 138/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5377 - accuracy: 0.7381 - val_loss: 0.5633 - val_accuracy: 0.7259\n",
            "Epoch 139/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5374 - accuracy: 0.7392 - val_loss: 0.5624 - val_accuracy: 0.7262\n",
            "Epoch 140/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5361 - accuracy: 0.7375 - val_loss: 0.5625 - val_accuracy: 0.7264\n",
            "Epoch 141/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5371 - accuracy: 0.7387 - val_loss: 0.5619 - val_accuracy: 0.7258\n",
            "Epoch 142/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5369 - accuracy: 0.7391 - val_loss: 0.5613 - val_accuracy: 0.7277\n",
            "Epoch 143/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5362 - accuracy: 0.7391 - val_loss: 0.5624 - val_accuracy: 0.7262\n",
            "Epoch 144/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5368 - accuracy: 0.7385 - val_loss: 0.5611 - val_accuracy: 0.7259\n",
            "Epoch 145/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5371 - accuracy: 0.7384 - val_loss: 0.5624 - val_accuracy: 0.7270\n",
            "Epoch 146/150\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5367 - accuracy: 0.7386 - val_loss: 0.5636 - val_accuracy: 0.7220\n",
            "Epoch 147/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5364 - accuracy: 0.7395 - val_loss: 0.5631 - val_accuracy: 0.7264\n",
            "Epoch 148/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5373 - accuracy: 0.7388 - val_loss: 0.5626 - val_accuracy: 0.7251\n",
            "Epoch 149/150\n",
            "858/858 [==============================] - 4s 4ms/step - loss: 0.5363 - accuracy: 0.7387 - val_loss: 0.5635 - val_accuracy: 0.7262\n",
            "Epoch 150/150\n",
            "858/858 [==============================] - 6s 7ms/step - loss: 0.5364 - accuracy: 0.7386 - val_loss: 0.5640 - val_accuracy: 0.7245\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ac96e153af0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_loss, model_accuracy = new_nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vv7WA62uv_OR",
        "outputId": "7b5a1db7-c210-4067-8b4f-38d7142db34a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "215/215 - 1s - loss: 0.5640 - accuracy: 0.7245 - 576ms/epoch - 3ms/step\n",
            "Loss: 0.5640274286270142, Accuracy: 0.7244898080825806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attemp 2"
      ],
      "metadata": {
        "id": "t7wAbZdexdSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
        "application_df = application_df.drop(columns=[\"EIN\", \"NAME\"])\n",
        "application_df.nunique()\n",
        "application_type_counts = application_df[\"APPLICATION_TYPE\"].value_counts().to_dict()\n",
        "cutoff_value = 100\n",
        "application_types_to_replace = []\n",
        "for atype in application_type_counts:\n",
        "    if application_type_counts[atype] < cutoff_value:\n",
        "        application_types_to_replace.append(atype)\n",
        "# Replace in dataframe\n",
        "# After creating the application_types_to_replace list,\n",
        "# another for loop is used to replace the application types in the \"APPLICATION_TYPE\" column of the DataFrame with \"Other\".\n",
        "# This ensures that the application types identified in the application_types_to_replace list are replaced accordingly.\n",
        "for app in application_types_to_replace:\n",
        "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
        "\n",
        "# Check to make sure binning was successful\n",
        "application_df['APPLICATION_TYPE'].value_counts()\n",
        "classifications_counts = application_df[\"CLASSIFICATION\"].value_counts().to_dict()\n",
        "cutoff_value_c = 100\n",
        "classifications_to_replace = []\n",
        "for classf in classifications_counts:\n",
        "    if classifications_counts[classf] < cutoff_value_c:\n",
        "        classifications_to_replace.append(classf)\n",
        "\n",
        "# Replace in dataframe\n",
        "for cls in classifications_to_replace:\n",
        "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
        "\n",
        "\n",
        "categorical_columns = ['APPLICATION_TYPE', 'AFFILIATION', 'CLASSIFICATION', 'USE_CASE', 'ORGANIZATION', 'INCOME_AMT', 'SPECIAL_CONSIDERATIONS']\n",
        "\n",
        "\n",
        "dummy_df = pd.get_dummies(application_df[categorical_columns], columns=categorical_columns)\n",
        "\n",
        "\n",
        "\n",
        "application_df.drop(columns=categorical_columns, inplace=True)\n",
        "\n",
        "application_df = pd.concat([application_df, dummy_df], axis=1)\n"
      ],
      "metadata": {
        "id": "j2VkVgH7xcaZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "HYRMk8LlyZJC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_nn = tf.keras.models.Sequential()\n",
        "\n",
        "# Input layer\n",
        "new_nn.add(tf.keras.layers.InputLayer(input_shape=(X_train_scaled.shape[1],)))\n",
        "\n",
        "# First hidden layer with 64 neurons and ReLU activation\n",
        "new_nn.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
        "\n",
        "# Dropout layer to reduce overfitting\n",
        "new_nn.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "# Second hidden layer with 32 neurons and ReLU activation\n",
        "new_nn.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
        "\n",
        "# Third hidden layer with 16 neurons and ReLU activation\n",
        "new_nn.add(tf.keras.layers.Dense(units=16, activation='relu'))\n",
        "\n",
        "# Fourth hidden layer with 8 neurons and ReLU activation\n",
        "new_nn.add(tf.keras.layers.Dense(units=8, activation='relu'))\n",
        "\n",
        "# Output layer with 1 neuron and sigmoid activation for binary classification\n",
        "new_nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Compile the new model\n",
        "new_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Check the summary of the new model\n",
        "new_nn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6THL7cgjyfxu",
        "outputId": "c8ec1db5-03c8-4728-a083-1e9244e0f670"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_5 (Dense)             (None, 64)                2816      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 8)                 136       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,569\n",
            "Trainable params: 5,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=150\n",
        "batch_size=32\n",
        "new_nn.fit(X_train_scaled, y_train, epochs=num_epochs, batch_size=batch_size, validation_data=(X_test_scaled, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JY7F36Ucyi-i",
        "outputId": "dad14591-6236-4dc3-f936-41214df8e729"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "858/858 [==============================] - 5s 3ms/step - loss: 0.5818 - accuracy: 0.7107 - val_loss: 0.5654 - val_accuracy: 0.7223\n",
            "Epoch 2/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5584 - accuracy: 0.7273 - val_loss: 0.5626 - val_accuracy: 0.7229\n",
            "Epoch 3/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5573 - accuracy: 0.7266 - val_loss: 0.5624 - val_accuracy: 0.7233\n",
            "Epoch 4/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5545 - accuracy: 0.7292 - val_loss: 0.5594 - val_accuracy: 0.7204\n",
            "Epoch 5/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5533 - accuracy: 0.7298 - val_loss: 0.5581 - val_accuracy: 0.7251\n",
            "Epoch 6/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5513 - accuracy: 0.7301 - val_loss: 0.5584 - val_accuracy: 0.7280\n",
            "Epoch 7/150\n",
            "858/858 [==============================] - 2s 2ms/step - loss: 0.5502 - accuracy: 0.7295 - val_loss: 0.5594 - val_accuracy: 0.7287\n",
            "Epoch 8/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5504 - accuracy: 0.7318 - val_loss: 0.5572 - val_accuracy: 0.7281\n",
            "Epoch 9/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5501 - accuracy: 0.7317 - val_loss: 0.5560 - val_accuracy: 0.7281\n",
            "Epoch 10/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5494 - accuracy: 0.7332 - val_loss: 0.5571 - val_accuracy: 0.7261\n",
            "Epoch 11/150\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5491 - accuracy: 0.7319 - val_loss: 0.5580 - val_accuracy: 0.7255\n",
            "Epoch 12/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5484 - accuracy: 0.7326 - val_loss: 0.5570 - val_accuracy: 0.7284\n",
            "Epoch 13/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5478 - accuracy: 0.7337 - val_loss: 0.5582 - val_accuracy: 0.7235\n",
            "Epoch 14/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5470 - accuracy: 0.7328 - val_loss: 0.5579 - val_accuracy: 0.7271\n",
            "Epoch 15/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5471 - accuracy: 0.7337 - val_loss: 0.5578 - val_accuracy: 0.7238\n",
            "Epoch 16/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5472 - accuracy: 0.7332 - val_loss: 0.5565 - val_accuracy: 0.7287\n",
            "Epoch 17/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5457 - accuracy: 0.7343 - val_loss: 0.5585 - val_accuracy: 0.7267\n",
            "Epoch 18/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5464 - accuracy: 0.7341 - val_loss: 0.5574 - val_accuracy: 0.7283\n",
            "Epoch 19/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5460 - accuracy: 0.7339 - val_loss: 0.5583 - val_accuracy: 0.7257\n",
            "Epoch 20/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5463 - accuracy: 0.7334 - val_loss: 0.5581 - val_accuracy: 0.7290\n",
            "Epoch 21/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5458 - accuracy: 0.7337 - val_loss: 0.5582 - val_accuracy: 0.7265\n",
            "Epoch 22/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5452 - accuracy: 0.7348 - val_loss: 0.5580 - val_accuracy: 0.7261\n",
            "Epoch 23/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5461 - accuracy: 0.7342 - val_loss: 0.5573 - val_accuracy: 0.7276\n",
            "Epoch 24/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5453 - accuracy: 0.7338 - val_loss: 0.5576 - val_accuracy: 0.7284\n",
            "Epoch 25/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5458 - accuracy: 0.7350 - val_loss: 0.5578 - val_accuracy: 0.7287\n",
            "Epoch 26/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5455 - accuracy: 0.7345 - val_loss: 0.5569 - val_accuracy: 0.7284\n",
            "Epoch 27/150\n",
            "858/858 [==============================] - 4s 5ms/step - loss: 0.5452 - accuracy: 0.7338 - val_loss: 0.5577 - val_accuracy: 0.7290\n",
            "Epoch 28/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5450 - accuracy: 0.7344 - val_loss: 0.5559 - val_accuracy: 0.7267\n",
            "Epoch 29/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5445 - accuracy: 0.7341 - val_loss: 0.5579 - val_accuracy: 0.7258\n",
            "Epoch 30/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5442 - accuracy: 0.7352 - val_loss: 0.5558 - val_accuracy: 0.7270\n",
            "Epoch 31/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5440 - accuracy: 0.7353 - val_loss: 0.5563 - val_accuracy: 0.7276\n",
            "Epoch 32/150\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5439 - accuracy: 0.7362 - val_loss: 0.5569 - val_accuracy: 0.7268\n",
            "Epoch 33/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5432 - accuracy: 0.7349 - val_loss: 0.5569 - val_accuracy: 0.7264\n",
            "Epoch 34/150\n",
            "858/858 [==============================] - 4s 4ms/step - loss: 0.5434 - accuracy: 0.7354 - val_loss: 0.5560 - val_accuracy: 0.7265\n",
            "Epoch 35/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5435 - accuracy: 0.7353 - val_loss: 0.5565 - val_accuracy: 0.7255\n",
            "Epoch 36/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5438 - accuracy: 0.7351 - val_loss: 0.5573 - val_accuracy: 0.7276\n",
            "Epoch 37/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5427 - accuracy: 0.7359 - val_loss: 0.5581 - val_accuracy: 0.7278\n",
            "Epoch 38/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5430 - accuracy: 0.7363 - val_loss: 0.5574 - val_accuracy: 0.7268\n",
            "Epoch 39/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5431 - accuracy: 0.7358 - val_loss: 0.5579 - val_accuracy: 0.7267\n",
            "Epoch 40/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5427 - accuracy: 0.7363 - val_loss: 0.5576 - val_accuracy: 0.7276\n",
            "Epoch 41/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5426 - accuracy: 0.7368 - val_loss: 0.5574 - val_accuracy: 0.7278\n",
            "Epoch 42/150\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5431 - accuracy: 0.7353 - val_loss: 0.5565 - val_accuracy: 0.7245\n",
            "Epoch 43/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5420 - accuracy: 0.7360 - val_loss: 0.5578 - val_accuracy: 0.7265\n",
            "Epoch 44/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5423 - accuracy: 0.7363 - val_loss: 0.5579 - val_accuracy: 0.7283\n",
            "Epoch 45/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5417 - accuracy: 0.7370 - val_loss: 0.5582 - val_accuracy: 0.7281\n",
            "Epoch 46/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5419 - accuracy: 0.7362 - val_loss: 0.5588 - val_accuracy: 0.7233\n",
            "Epoch 47/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5421 - accuracy: 0.7370 - val_loss: 0.5585 - val_accuracy: 0.7259\n",
            "Epoch 48/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5424 - accuracy: 0.7352 - val_loss: 0.5593 - val_accuracy: 0.7262\n",
            "Epoch 49/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5410 - accuracy: 0.7370 - val_loss: 0.5592 - val_accuracy: 0.7258\n",
            "Epoch 50/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5422 - accuracy: 0.7362 - val_loss: 0.5586 - val_accuracy: 0.7276\n",
            "Epoch 51/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5415 - accuracy: 0.7363 - val_loss: 0.5584 - val_accuracy: 0.7265\n",
            "Epoch 52/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5408 - accuracy: 0.7368 - val_loss: 0.5584 - val_accuracy: 0.7265\n",
            "Epoch 53/150\n",
            "858/858 [==============================] - 4s 4ms/step - loss: 0.5413 - accuracy: 0.7375 - val_loss: 0.5579 - val_accuracy: 0.7267\n",
            "Epoch 54/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5406 - accuracy: 0.7375 - val_loss: 0.5585 - val_accuracy: 0.7255\n",
            "Epoch 55/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5410 - accuracy: 0.7377 - val_loss: 0.5588 - val_accuracy: 0.7265\n",
            "Epoch 56/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5404 - accuracy: 0.7365 - val_loss: 0.5579 - val_accuracy: 0.7274\n",
            "Epoch 57/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5406 - accuracy: 0.7361 - val_loss: 0.5581 - val_accuracy: 0.7252\n",
            "Epoch 58/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5420 - accuracy: 0.7354 - val_loss: 0.5586 - val_accuracy: 0.7264\n",
            "Epoch 59/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5411 - accuracy: 0.7377 - val_loss: 0.5582 - val_accuracy: 0.7261\n",
            "Epoch 60/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5414 - accuracy: 0.7371 - val_loss: 0.5585 - val_accuracy: 0.7255\n",
            "Epoch 61/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5416 - accuracy: 0.7372 - val_loss: 0.5586 - val_accuracy: 0.7252\n",
            "Epoch 62/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5411 - accuracy: 0.7376 - val_loss: 0.5576 - val_accuracy: 0.7274\n",
            "Epoch 63/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5408 - accuracy: 0.7373 - val_loss: 0.5579 - val_accuracy: 0.7286\n",
            "Epoch 64/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5403 - accuracy: 0.7373 - val_loss: 0.5586 - val_accuracy: 0.7273\n",
            "Epoch 65/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5410 - accuracy: 0.7376 - val_loss: 0.5580 - val_accuracy: 0.7286\n",
            "Epoch 66/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5415 - accuracy: 0.7363 - val_loss: 0.5572 - val_accuracy: 0.7290\n",
            "Epoch 67/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5408 - accuracy: 0.7359 - val_loss: 0.5587 - val_accuracy: 0.7273\n",
            "Epoch 68/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5405 - accuracy: 0.7380 - val_loss: 0.5603 - val_accuracy: 0.7246\n",
            "Epoch 69/150\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5404 - accuracy: 0.7363 - val_loss: 0.5589 - val_accuracy: 0.7229\n",
            "Epoch 70/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5405 - accuracy: 0.7376 - val_loss: 0.5589 - val_accuracy: 0.7271\n",
            "Epoch 71/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5405 - accuracy: 0.7379 - val_loss: 0.5597 - val_accuracy: 0.7294\n",
            "Epoch 72/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5415 - accuracy: 0.7361 - val_loss: 0.5602 - val_accuracy: 0.7265\n",
            "Epoch 73/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5404 - accuracy: 0.7381 - val_loss: 0.5623 - val_accuracy: 0.7267\n",
            "Epoch 74/150\n",
            "858/858 [==============================] - 4s 4ms/step - loss: 0.5396 - accuracy: 0.7380 - val_loss: 0.5601 - val_accuracy: 0.7276\n",
            "Epoch 75/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5406 - accuracy: 0.7370 - val_loss: 0.5606 - val_accuracy: 0.7241\n",
            "Epoch 76/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5402 - accuracy: 0.7372 - val_loss: 0.5606 - val_accuracy: 0.7265\n",
            "Epoch 77/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5403 - accuracy: 0.7371 - val_loss: 0.5604 - val_accuracy: 0.7261\n",
            "Epoch 78/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5395 - accuracy: 0.7363 - val_loss: 0.5585 - val_accuracy: 0.7264\n",
            "Epoch 79/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5397 - accuracy: 0.7373 - val_loss: 0.5607 - val_accuracy: 0.7255\n",
            "Epoch 80/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5407 - accuracy: 0.7349 - val_loss: 0.5605 - val_accuracy: 0.7243\n",
            "Epoch 81/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5398 - accuracy: 0.7374 - val_loss: 0.5590 - val_accuracy: 0.7264\n",
            "Epoch 82/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5405 - accuracy: 0.7358 - val_loss: 0.5599 - val_accuracy: 0.7255\n",
            "Epoch 83/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5400 - accuracy: 0.7374 - val_loss: 0.5585 - val_accuracy: 0.7265\n",
            "Epoch 84/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5398 - accuracy: 0.7361 - val_loss: 0.5581 - val_accuracy: 0.7287\n",
            "Epoch 85/150\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5393 - accuracy: 0.7375 - val_loss: 0.5599 - val_accuracy: 0.7267\n",
            "Epoch 86/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5392 - accuracy: 0.7367 - val_loss: 0.5618 - val_accuracy: 0.7248\n",
            "Epoch 87/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5394 - accuracy: 0.7365 - val_loss: 0.5596 - val_accuracy: 0.7267\n",
            "Epoch 88/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5393 - accuracy: 0.7373 - val_loss: 0.5601 - val_accuracy: 0.7268\n",
            "Epoch 89/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5396 - accuracy: 0.7382 - val_loss: 0.5605 - val_accuracy: 0.7271\n",
            "Epoch 90/150\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5404 - accuracy: 0.7375 - val_loss: 0.5594 - val_accuracy: 0.7268\n",
            "Epoch 91/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5399 - accuracy: 0.7377 - val_loss: 0.5600 - val_accuracy: 0.7259\n",
            "Epoch 92/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5390 - accuracy: 0.7375 - val_loss: 0.5592 - val_accuracy: 0.7270\n",
            "Epoch 93/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5387 - accuracy: 0.7379 - val_loss: 0.5610 - val_accuracy: 0.7278\n",
            "Epoch 94/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5393 - accuracy: 0.7386 - val_loss: 0.5606 - val_accuracy: 0.7273\n",
            "Epoch 95/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5392 - accuracy: 0.7375 - val_loss: 0.5609 - val_accuracy: 0.7267\n",
            "Epoch 96/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5395 - accuracy: 0.7373 - val_loss: 0.5589 - val_accuracy: 0.7273\n",
            "Epoch 97/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5391 - accuracy: 0.7385 - val_loss: 0.5599 - val_accuracy: 0.7267\n",
            "Epoch 98/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5387 - accuracy: 0.7380 - val_loss: 0.5619 - val_accuracy: 0.7204\n",
            "Epoch 99/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5385 - accuracy: 0.7367 - val_loss: 0.5610 - val_accuracy: 0.7252\n",
            "Epoch 100/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5391 - accuracy: 0.7379 - val_loss: 0.5616 - val_accuracy: 0.7264\n",
            "Epoch 101/150\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5393 - accuracy: 0.7384 - val_loss: 0.5608 - val_accuracy: 0.7251\n",
            "Epoch 102/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5394 - accuracy: 0.7375 - val_loss: 0.5599 - val_accuracy: 0.7277\n",
            "Epoch 103/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5390 - accuracy: 0.7372 - val_loss: 0.5610 - val_accuracy: 0.7268\n",
            "Epoch 104/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5388 - accuracy: 0.7385 - val_loss: 0.5635 - val_accuracy: 0.7245\n",
            "Epoch 105/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5395 - accuracy: 0.7385 - val_loss: 0.5598 - val_accuracy: 0.7242\n",
            "Epoch 106/150\n",
            "858/858 [==============================] - 5s 6ms/step - loss: 0.5384 - accuracy: 0.7377 - val_loss: 0.5603 - val_accuracy: 0.7233\n",
            "Epoch 107/150\n",
            "858/858 [==============================] - 5s 5ms/step - loss: 0.5388 - accuracy: 0.7377 - val_loss: 0.5599 - val_accuracy: 0.7242\n",
            "Epoch 108/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5383 - accuracy: 0.7391 - val_loss: 0.5621 - val_accuracy: 0.7252\n",
            "Epoch 109/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5386 - accuracy: 0.7392 - val_loss: 0.5615 - val_accuracy: 0.7252\n",
            "Epoch 110/150\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5389 - accuracy: 0.7386 - val_loss: 0.5609 - val_accuracy: 0.7243\n",
            "Epoch 111/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5382 - accuracy: 0.7383 - val_loss: 0.5620 - val_accuracy: 0.7273\n",
            "Epoch 112/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5387 - accuracy: 0.7383 - val_loss: 0.5624 - val_accuracy: 0.7273\n",
            "Epoch 113/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5389 - accuracy: 0.7377 - val_loss: 0.5609 - val_accuracy: 0.7261\n",
            "Epoch 114/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5383 - accuracy: 0.7387 - val_loss: 0.5616 - val_accuracy: 0.7251\n",
            "Epoch 115/150\n",
            "858/858 [==============================] - 4s 4ms/step - loss: 0.5387 - accuracy: 0.7375 - val_loss: 0.5624 - val_accuracy: 0.7271\n",
            "Epoch 116/150\n",
            "858/858 [==============================] - 5s 6ms/step - loss: 0.5384 - accuracy: 0.7383 - val_loss: 0.5642 - val_accuracy: 0.7258\n",
            "Epoch 117/150\n",
            "858/858 [==============================] - 5s 5ms/step - loss: 0.5386 - accuracy: 0.7380 - val_loss: 0.5636 - val_accuracy: 0.7249\n",
            "Epoch 118/150\n",
            "858/858 [==============================] - 5s 6ms/step - loss: 0.5383 - accuracy: 0.7385 - val_loss: 0.5638 - val_accuracy: 0.7267\n",
            "Epoch 119/150\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5379 - accuracy: 0.7376 - val_loss: 0.5625 - val_accuracy: 0.7265\n",
            "Epoch 120/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5387 - accuracy: 0.7380 - val_loss: 0.5613 - val_accuracy: 0.7259\n",
            "Epoch 121/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5377 - accuracy: 0.7382 - val_loss: 0.5620 - val_accuracy: 0.7270\n",
            "Epoch 122/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5389 - accuracy: 0.7377 - val_loss: 0.5618 - val_accuracy: 0.7245\n",
            "Epoch 123/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5378 - accuracy: 0.7380 - val_loss: 0.5602 - val_accuracy: 0.7259\n",
            "Epoch 124/150\n",
            "858/858 [==============================] - 4s 5ms/step - loss: 0.5387 - accuracy: 0.7372 - val_loss: 0.5616 - val_accuracy: 0.7267\n",
            "Epoch 125/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5378 - accuracy: 0.7386 - val_loss: 0.5623 - val_accuracy: 0.7268\n",
            "Epoch 126/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5385 - accuracy: 0.7379 - val_loss: 0.5634 - val_accuracy: 0.7270\n",
            "Epoch 127/150\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5378 - accuracy: 0.7387 - val_loss: 0.5619 - val_accuracy: 0.7276\n",
            "Epoch 128/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5380 - accuracy: 0.7380 - val_loss: 0.5621 - val_accuracy: 0.7276\n",
            "Epoch 129/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5385 - accuracy: 0.7376 - val_loss: 0.5628 - val_accuracy: 0.7273\n",
            "Epoch 130/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5385 - accuracy: 0.7380 - val_loss: 0.5638 - val_accuracy: 0.7268\n",
            "Epoch 131/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5382 - accuracy: 0.7379 - val_loss: 0.5638 - val_accuracy: 0.7264\n",
            "Epoch 132/150\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5380 - accuracy: 0.7380 - val_loss: 0.5639 - val_accuracy: 0.7233\n",
            "Epoch 133/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5379 - accuracy: 0.7382 - val_loss: 0.5629 - val_accuracy: 0.7271\n",
            "Epoch 134/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5377 - accuracy: 0.7390 - val_loss: 0.5618 - val_accuracy: 0.7277\n",
            "Epoch 135/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5379 - accuracy: 0.7383 - val_loss: 0.5630 - val_accuracy: 0.7264\n",
            "Epoch 136/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5375 - accuracy: 0.7383 - val_loss: 0.5637 - val_accuracy: 0.7264\n",
            "Epoch 137/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5387 - accuracy: 0.7372 - val_loss: 0.5626 - val_accuracy: 0.7267\n",
            "Epoch 138/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5381 - accuracy: 0.7378 - val_loss: 0.5644 - val_accuracy: 0.7245\n",
            "Epoch 139/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5375 - accuracy: 0.7384 - val_loss: 0.5618 - val_accuracy: 0.7273\n",
            "Epoch 140/150\n",
            "858/858 [==============================] - 4s 5ms/step - loss: 0.5378 - accuracy: 0.7383 - val_loss: 0.5618 - val_accuracy: 0.7258\n",
            "Epoch 141/150\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5379 - accuracy: 0.7381 - val_loss: 0.5617 - val_accuracy: 0.7268\n",
            "Epoch 142/150\n",
            "858/858 [==============================] - 5s 6ms/step - loss: 0.5382 - accuracy: 0.7371 - val_loss: 0.5625 - val_accuracy: 0.7241\n",
            "Epoch 143/150\n",
            "858/858 [==============================] - 5s 6ms/step - loss: 0.5373 - accuracy: 0.7394 - val_loss: 0.5625 - val_accuracy: 0.7255\n",
            "Epoch 144/150\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5374 - accuracy: 0.7381 - val_loss: 0.5636 - val_accuracy: 0.7261\n",
            "Epoch 145/150\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5382 - accuracy: 0.7381 - val_loss: 0.5656 - val_accuracy: 0.7262\n",
            "Epoch 146/150\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5374 - accuracy: 0.7388 - val_loss: 0.5642 - val_accuracy: 0.7248\n",
            "Epoch 147/150\n",
            "858/858 [==============================] - 4s 5ms/step - loss: 0.5377 - accuracy: 0.7379 - val_loss: 0.5616 - val_accuracy: 0.7262\n",
            "Epoch 148/150\n",
            "858/858 [==============================] - 4s 4ms/step - loss: 0.5375 - accuracy: 0.7383 - val_loss: 0.5618 - val_accuracy: 0.7270\n",
            "Epoch 149/150\n",
            "858/858 [==============================] - 5s 6ms/step - loss: 0.5379 - accuracy: 0.7385 - val_loss: 0.5617 - val_accuracy: 0.7264\n",
            "Epoch 150/150\n",
            "858/858 [==============================] - 4s 5ms/step - loss: 0.5382 - accuracy: 0.7389 - val_loss: 0.5622 - val_accuracy: 0.7265\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ac95a63ae60>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_loss, model_accuracy = new_nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jE5sKjKkyl0p",
        "outputId": "8bb8568e-0f21-442f-f583-1fb234e7b088"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "215/215 - 0s - loss: 0.5622 - accuracy: 0.7265 - 309ms/epoch - 1ms/step\n",
            "Loss: 0.5622490644454956, Accuracy: 0.7265306115150452\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attempt 3:"
      ],
      "metadata": {
        "id": "8oPSqawLzujk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sophisticated_nn = tf.keras.models.Sequential()\n",
        "\n",
        "sophisticated_nn.add(tf.keras.layers.InputLayer(input_shape=(X_train_scaled.shape[1],)))\n",
        "\n",
        "\n",
        "sophisticated_nn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "\n",
        "\n",
        "sophisticated_nn.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "\n",
        "sophisticated_nn.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
        "\n",
        "\n",
        "sophisticated_nn.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
        "\n",
        "\n",
        "sophisticated_nn.add(tf.keras.layers.Dense(units=16, activation='relu'))\n",
        "\n",
        "\n",
        "sophisticated_nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "sophisticated_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "id": "fJ_Bjz63zvop"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=50\n",
        "batch_size=32\n",
        "sophisticated_nn.fit(X_train_scaled, y_train, epochs=num_epochs, batch_size=batch_size, validation_data=(X_test_scaled, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbltMebk0Ju6",
        "outputId": "650bfac8-abf2-426c-d9be-ce3d999fc1d0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "858/858 [==============================] - 6s 4ms/step - loss: 0.5707 - accuracy: 0.7200 - val_loss: 0.5649 - val_accuracy: 0.7276\n",
            "Epoch 2/50\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5567 - accuracy: 0.7291 - val_loss: 0.5622 - val_accuracy: 0.7227\n",
            "Epoch 3/50\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5534 - accuracy: 0.7296 - val_loss: 0.5602 - val_accuracy: 0.7246\n",
            "Epoch 4/50\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5524 - accuracy: 0.7295 - val_loss: 0.5568 - val_accuracy: 0.7286\n",
            "Epoch 5/50\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5507 - accuracy: 0.7311 - val_loss: 0.5594 - val_accuracy: 0.7214\n",
            "Epoch 6/50\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5499 - accuracy: 0.7315 - val_loss: 0.5606 - val_accuracy: 0.7255\n",
            "Epoch 7/50\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5490 - accuracy: 0.7329 - val_loss: 0.5589 - val_accuracy: 0.7268\n",
            "Epoch 8/50\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5486 - accuracy: 0.7328 - val_loss: 0.5591 - val_accuracy: 0.7259\n",
            "Epoch 9/50\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5478 - accuracy: 0.7332 - val_loss: 0.5565 - val_accuracy: 0.7294\n",
            "Epoch 10/50\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5462 - accuracy: 0.7338 - val_loss: 0.5587 - val_accuracy: 0.7278\n",
            "Epoch 11/50\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5469 - accuracy: 0.7333 - val_loss: 0.5568 - val_accuracy: 0.7276\n",
            "Epoch 12/50\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5465 - accuracy: 0.7329 - val_loss: 0.5571 - val_accuracy: 0.7262\n",
            "Epoch 13/50\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5467 - accuracy: 0.7338 - val_loss: 0.5593 - val_accuracy: 0.7273\n",
            "Epoch 14/50\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5452 - accuracy: 0.7339 - val_loss: 0.5576 - val_accuracy: 0.7290\n",
            "Epoch 15/50\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5452 - accuracy: 0.7343 - val_loss: 0.5551 - val_accuracy: 0.7289\n",
            "Epoch 16/50\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5441 - accuracy: 0.7349 - val_loss: 0.5583 - val_accuracy: 0.7264\n",
            "Epoch 17/50\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5443 - accuracy: 0.7344 - val_loss: 0.5585 - val_accuracy: 0.7270\n",
            "Epoch 18/50\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5442 - accuracy: 0.7348 - val_loss: 0.5586 - val_accuracy: 0.7248\n",
            "Epoch 19/50\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5437 - accuracy: 0.7346 - val_loss: 0.5578 - val_accuracy: 0.7289\n",
            "Epoch 20/50\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5433 - accuracy: 0.7355 - val_loss: 0.5581 - val_accuracy: 0.7283\n",
            "Epoch 21/50\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5431 - accuracy: 0.7351 - val_loss: 0.5572 - val_accuracy: 0.7274\n",
            "Epoch 22/50\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5434 - accuracy: 0.7334 - val_loss: 0.5571 - val_accuracy: 0.7255\n",
            "Epoch 23/50\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5428 - accuracy: 0.7359 - val_loss: 0.5561 - val_accuracy: 0.7270\n",
            "Epoch 24/50\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5430 - accuracy: 0.7356 - val_loss: 0.5586 - val_accuracy: 0.7265\n",
            "Epoch 25/50\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5431 - accuracy: 0.7351 - val_loss: 0.5573 - val_accuracy: 0.7259\n",
            "Epoch 26/50\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5427 - accuracy: 0.7355 - val_loss: 0.5582 - val_accuracy: 0.7262\n",
            "Epoch 27/50\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5419 - accuracy: 0.7375 - val_loss: 0.5587 - val_accuracy: 0.7238\n",
            "Epoch 28/50\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5430 - accuracy: 0.7358 - val_loss: 0.5575 - val_accuracy: 0.7280\n",
            "Epoch 29/50\n",
            "858/858 [==============================] - 4s 5ms/step - loss: 0.5424 - accuracy: 0.7358 - val_loss: 0.5579 - val_accuracy: 0.7243\n",
            "Epoch 30/50\n",
            "858/858 [==============================] - 7s 8ms/step - loss: 0.5415 - accuracy: 0.7359 - val_loss: 0.5582 - val_accuracy: 0.7268\n",
            "Epoch 31/50\n",
            "858/858 [==============================] - 5s 6ms/step - loss: 0.5417 - accuracy: 0.7361 - val_loss: 0.5575 - val_accuracy: 0.7252\n",
            "Epoch 32/50\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5412 - accuracy: 0.7373 - val_loss: 0.5578 - val_accuracy: 0.7258\n",
            "Epoch 33/50\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5413 - accuracy: 0.7352 - val_loss: 0.5577 - val_accuracy: 0.7246\n",
            "Epoch 34/50\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5412 - accuracy: 0.7363 - val_loss: 0.5581 - val_accuracy: 0.7245\n",
            "Epoch 35/50\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5408 - accuracy: 0.7357 - val_loss: 0.5570 - val_accuracy: 0.7249\n",
            "Epoch 36/50\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5403 - accuracy: 0.7375 - val_loss: 0.5591 - val_accuracy: 0.7257\n",
            "Epoch 37/50\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5405 - accuracy: 0.7372 - val_loss: 0.5582 - val_accuracy: 0.7241\n",
            "Epoch 38/50\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5404 - accuracy: 0.7372 - val_loss: 0.5592 - val_accuracy: 0.7259\n",
            "Epoch 39/50\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5406 - accuracy: 0.7370 - val_loss: 0.5593 - val_accuracy: 0.7274\n",
            "Epoch 40/50\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5402 - accuracy: 0.7376 - val_loss: 0.5584 - val_accuracy: 0.7246\n",
            "Epoch 41/50\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5399 - accuracy: 0.7372 - val_loss: 0.5577 - val_accuracy: 0.7270\n",
            "Epoch 42/50\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5399 - accuracy: 0.7365 - val_loss: 0.5588 - val_accuracy: 0.7267\n",
            "Epoch 43/50\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5396 - accuracy: 0.7379 - val_loss: 0.5585 - val_accuracy: 0.7258\n",
            "Epoch 44/50\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5398 - accuracy: 0.7375 - val_loss: 0.5578 - val_accuracy: 0.7278\n",
            "Epoch 45/50\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5391 - accuracy: 0.7373 - val_loss: 0.5599 - val_accuracy: 0.7254\n",
            "Epoch 46/50\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5397 - accuracy: 0.7376 - val_loss: 0.5594 - val_accuracy: 0.7245\n",
            "Epoch 47/50\n",
            "858/858 [==============================] - 4s 4ms/step - loss: 0.5389 - accuracy: 0.7377 - val_loss: 0.5598 - val_accuracy: 0.7261\n",
            "Epoch 48/50\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5388 - accuracy: 0.7380 - val_loss: 0.5617 - val_accuracy: 0.7257\n",
            "Epoch 49/50\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5388 - accuracy: 0.7384 - val_loss: 0.5618 - val_accuracy: 0.7262\n",
            "Epoch 50/50\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5396 - accuracy: 0.7371 - val_loss: 0.5615 - val_accuracy: 0.7252\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ac95a632fe0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_loss, model_accuracy = sophisticated_nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjI5incL0gd7",
        "outputId": "e8f53f22-de23-4328-8578-ee2c15cabde7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "215/215 - 0s - loss: 0.5615 - accuracy: 0.7252 - 467ms/epoch - 2ms/step\n",
            "Loss: 0.5614736676216125, Accuracy: 0.725218653678894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YAqNS2_p1FIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attempt 4:"
      ],
      "metadata": {
        "id": "_QmNd2qo1UZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
        "application_df = application_df.drop(columns=[\"EIN\", \"NAME\"])\n",
        "application_df.nunique()\n",
        "application_type_counts = application_df[\"APPLICATION_TYPE\"].value_counts().to_dict()\n",
        "cutoff_value = 527\n",
        "application_types_to_replace = []\n",
        "for atype in application_type_counts:\n",
        "    if application_type_counts[atype] < cutoff_value:\n",
        "        application_types_to_replace.append(atype)\n",
        "# Replace in dataframe\n",
        "# After creating the application_types_to_replace list,\n",
        "# another for loop is used to replace the application types in the \"APPLICATION_TYPE\" column of the DataFrame with \"Other\".\n",
        "# This ensures that the application types identified in the application_types_to_replace list are replaced accordingly.\n",
        "for app in application_types_to_replace:\n",
        "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
        "\n",
        "# Check to make sure binning was successful\n",
        "application_df['APPLICATION_TYPE'].value_counts()\n",
        "classifications_counts = application_df[\"CLASSIFICATION\"].value_counts().to_dict()\n",
        "cutoff_value_c = 1882\n",
        "classifications_to_replace = []\n",
        "for classf in classifications_counts:\n",
        "    if classifications_counts[classf] < cutoff_value_c:\n",
        "        classifications_to_replace.append(classf)\n",
        "\n",
        "# Replace in dataframe\n",
        "for cls in classifications_to_replace:\n",
        "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
        "\n",
        "\n",
        "categorical_columns = ['APPLICATION_TYPE', 'AFFILIATION', 'CLASSIFICATION', 'USE_CASE', 'ORGANIZATION', 'INCOME_AMT', 'SPECIAL_CONSIDERATIONS']\n",
        "\n",
        "\n",
        "dummy_df = pd.get_dummies(application_df[categorical_columns], columns=categorical_columns)\n",
        "\n",
        "\n",
        "\n",
        "application_df.drop(columns=categorical_columns, inplace=True)\n",
        "\n",
        "application_df = pd.concat([application_df, dummy_df], axis=1)\n"
      ],
      "metadata": {
        "id": "ieMvAhsy1Vbo"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "SX-jZO6e1WZQ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sophisticated_nn = tf.keras.models.Sequential()\n",
        "\n",
        "sophisticated_nn.add(tf.keras.layers.InputLayer(input_shape=(X_train_scaled.shape[1],)))\n",
        "\n",
        "\n",
        "sophisticated_nn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "\n",
        "\n",
        "sophisticated_nn.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "\n",
        "sophisticated_nn.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
        "\n",
        "\n",
        "sophisticated_nn.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
        "\n",
        "\n",
        "sophisticated_nn.add(tf.keras.layers.Dense(units=16, activation='relu'))\n",
        "\n",
        "\n",
        "sophisticated_nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "sophisticated_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "id": "8E8FcAB21bwA"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=80\n",
        "batch_size=32\n",
        "sophisticated_nn.fit(X_train_scaled, y_train, epochs=num_epochs, batch_size=batch_size, validation_data=(X_test_scaled, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYQsu7F21fIy",
        "outputId": "bc6d4947-3471-4ba5-fd50-03c3bc9ff308"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "858/858 [==============================] - 4s 3ms/step - loss: 0.5714 - accuracy: 0.7197 - val_loss: 0.5633 - val_accuracy: 0.7227\n",
            "Epoch 2/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5562 - accuracy: 0.7293 - val_loss: 0.5611 - val_accuracy: 0.7200\n",
            "Epoch 3/80\n",
            "858/858 [==============================] - 4s 4ms/step - loss: 0.5539 - accuracy: 0.7304 - val_loss: 0.5605 - val_accuracy: 0.7273\n",
            "Epoch 4/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5524 - accuracy: 0.7306 - val_loss: 0.5632 - val_accuracy: 0.7270\n",
            "Epoch 5/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5509 - accuracy: 0.7310 - val_loss: 0.5583 - val_accuracy: 0.7265\n",
            "Epoch 6/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5487 - accuracy: 0.7329 - val_loss: 0.5609 - val_accuracy: 0.7286\n",
            "Epoch 7/80\n",
            "858/858 [==============================] - 4s 4ms/step - loss: 0.5485 - accuracy: 0.7325 - val_loss: 0.5563 - val_accuracy: 0.7284\n",
            "Epoch 8/80\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5481 - accuracy: 0.7335 - val_loss: 0.5581 - val_accuracy: 0.7297\n",
            "Epoch 9/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5475 - accuracy: 0.7323 - val_loss: 0.5592 - val_accuracy: 0.7271\n",
            "Epoch 10/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5474 - accuracy: 0.7334 - val_loss: 0.5592 - val_accuracy: 0.7305\n",
            "Epoch 11/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5467 - accuracy: 0.7332 - val_loss: 0.5573 - val_accuracy: 0.7259\n",
            "Epoch 12/80\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5458 - accuracy: 0.7336 - val_loss: 0.5568 - val_accuracy: 0.7296\n",
            "Epoch 13/80\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5459 - accuracy: 0.7352 - val_loss: 0.5604 - val_accuracy: 0.7216\n",
            "Epoch 14/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5456 - accuracy: 0.7337 - val_loss: 0.5573 - val_accuracy: 0.7289\n",
            "Epoch 15/80\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5450 - accuracy: 0.7340 - val_loss: 0.5592 - val_accuracy: 0.7262\n",
            "Epoch 16/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5439 - accuracy: 0.7346 - val_loss: 0.5561 - val_accuracy: 0.7308\n",
            "Epoch 17/80\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5441 - accuracy: 0.7346 - val_loss: 0.5586 - val_accuracy: 0.7289\n",
            "Epoch 18/80\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5437 - accuracy: 0.7357 - val_loss: 0.5569 - val_accuracy: 0.7287\n",
            "Epoch 19/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5430 - accuracy: 0.7369 - val_loss: 0.5576 - val_accuracy: 0.7259\n",
            "Epoch 20/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5427 - accuracy: 0.7363 - val_loss: 0.5600 - val_accuracy: 0.7292\n",
            "Epoch 21/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5443 - accuracy: 0.7348 - val_loss: 0.5566 - val_accuracy: 0.7274\n",
            "Epoch 22/80\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5424 - accuracy: 0.7352 - val_loss: 0.5574 - val_accuracy: 0.7261\n",
            "Epoch 23/80\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5420 - accuracy: 0.7360 - val_loss: 0.5592 - val_accuracy: 0.7287\n",
            "Epoch 24/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5429 - accuracy: 0.7350 - val_loss: 0.5582 - val_accuracy: 0.7300\n",
            "Epoch 25/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5421 - accuracy: 0.7371 - val_loss: 0.5580 - val_accuracy: 0.7283\n",
            "Epoch 26/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5415 - accuracy: 0.7354 - val_loss: 0.5595 - val_accuracy: 0.7300\n",
            "Epoch 27/80\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5427 - accuracy: 0.7351 - val_loss: 0.5577 - val_accuracy: 0.7292\n",
            "Epoch 28/80\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5418 - accuracy: 0.7361 - val_loss: 0.5600 - val_accuracy: 0.7277\n",
            "Epoch 29/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5409 - accuracy: 0.7364 - val_loss: 0.5570 - val_accuracy: 0.7312\n",
            "Epoch 30/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5416 - accuracy: 0.7361 - val_loss: 0.5574 - val_accuracy: 0.7296\n",
            "Epoch 31/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5414 - accuracy: 0.7366 - val_loss: 0.5593 - val_accuracy: 0.7271\n",
            "Epoch 32/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5410 - accuracy: 0.7367 - val_loss: 0.5582 - val_accuracy: 0.7270\n",
            "Epoch 33/80\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5408 - accuracy: 0.7371 - val_loss: 0.5579 - val_accuracy: 0.7277\n",
            "Epoch 34/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5416 - accuracy: 0.7365 - val_loss: 0.5581 - val_accuracy: 0.7274\n",
            "Epoch 35/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5404 - accuracy: 0.7373 - val_loss: 0.5598 - val_accuracy: 0.7233\n",
            "Epoch 36/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5407 - accuracy: 0.7371 - val_loss: 0.5571 - val_accuracy: 0.7280\n",
            "Epoch 37/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5406 - accuracy: 0.7375 - val_loss: 0.5575 - val_accuracy: 0.7264\n",
            "Epoch 38/80\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5404 - accuracy: 0.7366 - val_loss: 0.5578 - val_accuracy: 0.7267\n",
            "Epoch 39/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5396 - accuracy: 0.7374 - val_loss: 0.5589 - val_accuracy: 0.7273\n",
            "Epoch 40/80\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5398 - accuracy: 0.7377 - val_loss: 0.5565 - val_accuracy: 0.7294\n",
            "Epoch 41/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5400 - accuracy: 0.7380 - val_loss: 0.5583 - val_accuracy: 0.7284\n",
            "Epoch 42/80\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5402 - accuracy: 0.7363 - val_loss: 0.5595 - val_accuracy: 0.7267\n",
            "Epoch 43/80\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5395 - accuracy: 0.7367 - val_loss: 0.5597 - val_accuracy: 0.7217\n",
            "Epoch 44/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5396 - accuracy: 0.7367 - val_loss: 0.5588 - val_accuracy: 0.7281\n",
            "Epoch 45/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5396 - accuracy: 0.7368 - val_loss: 0.5578 - val_accuracy: 0.7276\n",
            "Epoch 46/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5391 - accuracy: 0.7372 - val_loss: 0.5579 - val_accuracy: 0.7292\n",
            "Epoch 47/80\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5393 - accuracy: 0.7365 - val_loss: 0.5611 - val_accuracy: 0.7255\n",
            "Epoch 48/80\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5389 - accuracy: 0.7380 - val_loss: 0.5580 - val_accuracy: 0.7280\n",
            "Epoch 49/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5386 - accuracy: 0.7375 - val_loss: 0.5598 - val_accuracy: 0.7276\n",
            "Epoch 50/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5391 - accuracy: 0.7367 - val_loss: 0.5584 - val_accuracy: 0.7308\n",
            "Epoch 51/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5384 - accuracy: 0.7378 - val_loss: 0.5589 - val_accuracy: 0.7278\n",
            "Epoch 52/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5380 - accuracy: 0.7373 - val_loss: 0.5617 - val_accuracy: 0.7262\n",
            "Epoch 53/80\n",
            "858/858 [==============================] - 4s 4ms/step - loss: 0.5385 - accuracy: 0.7376 - val_loss: 0.5603 - val_accuracy: 0.7262\n",
            "Epoch 54/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5385 - accuracy: 0.7362 - val_loss: 0.5590 - val_accuracy: 0.7280\n",
            "Epoch 55/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5383 - accuracy: 0.7372 - val_loss: 0.5603 - val_accuracy: 0.7261\n",
            "Epoch 56/80\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5377 - accuracy: 0.7374 - val_loss: 0.5620 - val_accuracy: 0.7248\n",
            "Epoch 57/80\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5378 - accuracy: 0.7374 - val_loss: 0.5614 - val_accuracy: 0.7278\n",
            "Epoch 58/80\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5388 - accuracy: 0.7382 - val_loss: 0.5622 - val_accuracy: 0.7270\n",
            "Epoch 59/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5383 - accuracy: 0.7382 - val_loss: 0.5607 - val_accuracy: 0.7267\n",
            "Epoch 60/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5381 - accuracy: 0.7371 - val_loss: 0.5616 - val_accuracy: 0.7262\n",
            "Epoch 61/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5380 - accuracy: 0.7377 - val_loss: 0.5599 - val_accuracy: 0.7248\n",
            "Epoch 62/80\n",
            "858/858 [==============================] - 3s 3ms/step - loss: 0.5378 - accuracy: 0.7381 - val_loss: 0.5631 - val_accuracy: 0.7264\n",
            "Epoch 63/80\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5374 - accuracy: 0.7382 - val_loss: 0.5614 - val_accuracy: 0.7238\n",
            "Epoch 64/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5375 - accuracy: 0.7374 - val_loss: 0.5627 - val_accuracy: 0.7271\n",
            "Epoch 65/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5382 - accuracy: 0.7380 - val_loss: 0.5628 - val_accuracy: 0.7262\n",
            "Epoch 66/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5377 - accuracy: 0.7371 - val_loss: 0.5628 - val_accuracy: 0.7276\n",
            "Epoch 67/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5374 - accuracy: 0.7371 - val_loss: 0.5638 - val_accuracy: 0.7284\n",
            "Epoch 68/80\n",
            "858/858 [==============================] - 3s 4ms/step - loss: 0.5376 - accuracy: 0.7370 - val_loss: 0.5635 - val_accuracy: 0.7278\n",
            "Epoch 69/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5386 - accuracy: 0.7377 - val_loss: 0.5611 - val_accuracy: 0.7277\n",
            "Epoch 70/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5376 - accuracy: 0.7381 - val_loss: 0.5614 - val_accuracy: 0.7286\n",
            "Epoch 71/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5369 - accuracy: 0.7377 - val_loss: 0.5629 - val_accuracy: 0.7274\n",
            "Epoch 72/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5378 - accuracy: 0.7381 - val_loss: 0.5630 - val_accuracy: 0.7261\n",
            "Epoch 73/80\n",
            "858/858 [==============================] - 4s 4ms/step - loss: 0.5375 - accuracy: 0.7382 - val_loss: 0.5645 - val_accuracy: 0.7280\n",
            "Epoch 74/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5371 - accuracy: 0.7383 - val_loss: 0.5632 - val_accuracy: 0.7283\n",
            "Epoch 75/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5369 - accuracy: 0.7386 - val_loss: 0.5676 - val_accuracy: 0.7258\n",
            "Epoch 76/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5372 - accuracy: 0.7372 - val_loss: 0.5662 - val_accuracy: 0.7243\n",
            "Epoch 77/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5368 - accuracy: 0.7394 - val_loss: 0.5657 - val_accuracy: 0.7243\n",
            "Epoch 78/80\n",
            "858/858 [==============================] - 5s 6ms/step - loss: 0.5369 - accuracy: 0.7388 - val_loss: 0.5648 - val_accuracy: 0.7255\n",
            "Epoch 79/80\n",
            "858/858 [==============================] - 4s 4ms/step - loss: 0.5365 - accuracy: 0.7393 - val_loss: 0.5653 - val_accuracy: 0.7271\n",
            "Epoch 80/80\n",
            "858/858 [==============================] - 2s 3ms/step - loss: 0.5372 - accuracy: 0.7376 - val_loss: 0.5636 - val_accuracy: 0.7259\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ac95a27a0e0>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_loss, model_accuracy = sophisticated_nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqGtHoBM1kyJ",
        "outputId": "3556f61d-1004-43b6-b85b-65e0ea35c8c2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "215/215 - 0s - loss: 0.5636 - accuracy: 0.7259 - 454ms/epoch - 2ms/step\n",
            "Loss: 0.5636117458343506, Accuracy: 0.7259474992752075\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pKa7LBQG2Zoq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}